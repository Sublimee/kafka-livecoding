# Topic Retention (очистка топика)

Этот механизм служит основным способом удаления данных из Kafka и включен по умолчанию с помощью настройки брокера _log.cleanup.policy = [delete]_. 

Мы можем настроить его работу по времени и/или по размеру партиции. Это зависит от вашего сценария использования и требований к хранению.
Настройки брокера по умолчанию позволят храниться данным в топике 168 часов (7 дней) и не ограничены по объему (пока дисковое пространство на брокере не заполнится до предела).
По умолчанию Kafka проверяет, нужно ли удалить данные каждые 5 минут (значение _log.retention.check.interval.ms_ можно найти в логах при старте брокера). Давайте уменьшим этот интервал – будем делать проверку раз в секунду.
Остановим брокер Kafka и открываем файл на редактирование:

```
vi config/server.properties
```

выставляем нужное значение для теста:

```
log.retention.check.interval.ms=1000
```

и запускаем брокер:

```
./bin/kafka-server-start.sh config/server.properties
```

Для лучшей наглядности настроим топик _test_ на удаление сообщений, время жизни которых более десяти секунд:

```
./bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name test --alter --add-config retention.ms=10000
```

В консоли мы должны увидеть:

```
Completed updating config for topic test.
```

Запустив заново консьюмер, мы увидим, что сообщения, действительно, удалились. В логе брокера видим соответствующее сообщение:

```
INFO [UnifiedLog partition=test-0, dir=/tmp/kafka-logs] Deleting segment LogSegment(baseOffset=7, size=69, lastModifiedTime=1675783773147, largestRecordTimestamp=Some(1675783772146)) due to retention time 10000ms breach based on the largest record timestamp in the segment (kafka.log.UnifiedLog)
```

Практику можно было бы считать завершенной, но давайте проведем дополнительный эксперимент. В терминале запустим вот такую конструкцию, которая раз в секунду будет отправлять сообщения в кластер:

```
for i in $(seq 1 2000); do echo "${i}"; sleep 1; done | ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test --sync
```

Читая сообщения даже спустя минуту, мы по-прежнему видим старые сообщения:

```
./bin/kafka-console-consumer.sh --topic test --bootstrap-server localhost:9092 --consumer-property auto.offset.reset=earliest
```

Для того чтобы понять, что происходит, мы должны вспомнить, как хранятся данные топик-партиции на диске. 

<details>
  <summary>Спойлер</summary>
  
  Каждая партиция состоит из набора файлов, называемого сегментами. Новые сообщения записываются в открытый/головной/активный сегмент. Закрытые сегменты хранятся на диске и не могут быть дополнены новыми записями. Удаление происходит посегментно, т.е. файл сегмента удаляется целиком. Используется следующий алгоритм: 
  1. берется очередной закрытый сегмент
  2. вычисляется разница между максимальным timestamp сообщений сегмента и текущим временем
  3. эта разница сравнивается с retention.ms и если она больше, то сегмент помечается к удалению
  4. через file.delete.delay.ms файлы удаляются отдельным потоком с файловой системы

  ![Хранение данных в Kafka](https://user-images.githubusercontent.com/13710048/236379520-84d2ef00-bc30-4244-8111-519497c4fbf6.png)
  
</details>

Не дожидаясь окончания работы скрипта для генерации данных для консьюмера, заглянем в папку с данными исследуемой топик-партиции и увидим активный сегмент:

```
ls -la /tmp/kafka-logs/test-0/
```

```
total 64
drwxrwxr-x  2 subli subli     4096 фев  9 07:25 .
drwxrwxr-x 53 subli subli     4096 фев  9 07:31 ..
-rw-rw-r--  1 subli subli      102 фев  7 17:47 00000000000000000004.snapshot
-rw-rw-r--  1 subli subli 10485760 фев  9 07:31 00000000000000003608.index
-rw-rw-r--  1 subli subli    25617 фев  9 07:31 00000000000000003608.log
-rw-rw-r--  1 subli subli      240 фев  7 19:35 00000000000000003608.snapshot
-rw-rw-r--  1 subli subli 10485756 фев  9 07:31 00000000000000003608.timeindex
-rw-rw-r--  1 subli subli       11 фев  7 19:35 leader-epoch-checkpoint
-rw-rw-r--  1 subli subli       43 фев  6 19:33 partition.metadata
```

Наибольший интерес для нас представляет файл _.log_ (файл активного сегмента). Этот файл содержит сообщения топик-партиции, начиная с офсета указанного в имени файла. Так как мы писали в топик с периодичностью в 1 секунду (менее retention.ms), то мы постоянно увеличивали максимальный timestamp сообщений, находящихся в сегменте, а значит сегмент продолжал быть активным. В этом случае для удаления старых данных нам бы пришлось ждать, пока активный сегмент не станет больше, чем segment.bytes или его время жизни не будет больше segment.ms (работают одновременно).
Остановим скрипт генерации данных для консьюмера или дождемся его завершения. Заглянув в папку с данными исследуемой топик-партиции, видим активный сегмент (а также закрытый сегмент, помеченные как deleted).

```
ls -la /tmp/kafka-logs/test-0
```

```
total 68
drwxrwxr-x  2 subli subli     4096 фев  9 07:31 .
drwxrwxr-x 53 subli subli     4096 фев  9 07:32 ..
-rw-rw-r--  1 subli subli      102 фев  7 17:47 00000000000000000004.snapshot
-rw-rw-r--  1 subli subli       48 фев  9 07:31 00000000000000003608.index.deleted
-rw-rw-r--  1 subli subli    27267 фев  9 07:31 00000000000000003608.log.deleted
-rw-rw-r--  1 subli subli      240 фев  7 19:35 00000000000000003608.snapshot.deleted
-rw-rw-r--  1 subli subli       84 фев  9 07:31 00000000000000003608.timeindex.deleted
-rw-rw-r--  1 subli subli        0 фев  9 07:31 00000000000000003973.log
-rw-rw-r--  1 subli subli      240 фев  9 07:31 00000000000000003973.snapshot
-rw-rw-r--  1 subli subli 10485756 фев  9 07:31 00000000000000003973.timeindex
-rw-rw-r--  1 subli subli       11 фев  9 07:31 leader-epoch-checkpoint
-rw-rw-r--  1 subli subli       43 фев  6 19:33 partition.metadata
```

Через некоторое время они будут удалены:

```
ls -la /tmp/kafka-logs/test-0/
```

```
total 24
drwxrwxr-x  2 subli subli     4096 фев  9 07:32 .
drwxrwxr-x 53 subli subli     4096 фев  9 07:37 ..
-rw-rw-r--  1 subli subli      102 фев  7 17:47 00000000000000000004.snapshot
-rw-rw-r--  1 subli subli        0 фев  9 07:31 00000000000000003973.log
-rw-rw-r--  1 subli subli      240 фев  9 07:31 00000000000000003973.snapshot
-rw-rw-r--  1 subli subli 10485756 фев  9 07:31 00000000000000003973.timeindex
-rw-rw-r--  1 subli subli       11 фев  9 07:31 leader-epoch-checkpoint
-rw-rw-r--  1 subli subli       43 фев  6 19:33 partition.metadata
```

Выставим более частую ротацию сегментов нашему топику (раз в 10 секунд):

```
./bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name test --alter --add-config segment.ms=10000
```

Подадим нагрузку и начнем отслеживание папки с данными исследуемой топик-партиции с помощью команды:

```
watch -n 1 ls -la /tmp/kafka-logs/test-0/
```

Мы видим ротацию сегмента в логе и, как следствие, процесс удаления данных из топик-партиции.
С разнообразием настроек удаления данных из топиков поможет разобраться следующая таблица:


| Название параметра на уровне брокера | Название параметра на уровне топика | Значение по умолчанию | Влияние |
|---------------------|---------------------|---------------------|---------------------|
| log.segment.bytes | segment.bytes | 1 GiB | Максимальный размер одного файла лога партиции (сегмента) |
| log.roll.hours <br> log.roll.ms | segment.ms | 168 (часов) <br> – | Максимальное время до создания нового файла лога партиции (сегмента) |
| log.retention.bytes | retention.bytes | -1 (никогда не удалять) | Максимальный размер занимаемый партицией, после которого начнется удаление старых данных |
| log.retention.ms <br> log.retention.minutes <br> log.retention.hours | retention.ms | – <br> – <br> 168 (часов) | Максимальное время жизни файла лога партиции, после которого начнется удаление старых данных |
| log.retention.check.interval.ms | – | 300000 (5 минут) | Период в миллисекундах через который log cleaner проверяет необходимость удаления файлов логов |
| log.segment.delete.delay.ms | file.delete.delay.ms | 60000 (1 минута) | Время до удаления файла лога с файловой системы после того, как он был помечен к удалению |

Уровень брокера содержит значения по умолчанию для всех настроек и часто имеет префикс _log_. Например, _log.retention.ms_ – это глобальный дефолт retention-а для всех топиков, который задается в конфигурационном файле _server.properties_. Topic-level конфигуграции – это оверрайды для отдельных топиков, которые мы задавали через команду _kafka-configs.sh_. Их значения хранятся в ZooKeeper.
При расчете необходимых ресурсов важно помнить, что, например, _log.retention.bytes_ и _log.retention.hours_ относятся не к топику целиком, а к партиции.

# Резюме по уроку

Если вы хотите затащить Kafka в прод, то:
* заранее спланируйте ваши железные ресурсы
* убедитесь в правильной настройке очистки топиков
